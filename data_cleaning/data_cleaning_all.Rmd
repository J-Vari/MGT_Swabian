---
title: "Data cleaning"
author: "Judit Vari"
date: "25 7 2024"
output: html_document
editor_options: 
  chunk_output_type: console
---
# load libraries for cleaning
```{r libraries, include=FALSE}
library (dplyr)
library(broom)
library(tidyverse)
library(corrr)
library(ggcorrplot)
library(car)
library(readr)
library(here)
library(stringr)
library(tidytext)
options(scipen=999)
```
# *Tasks male only*
## Audio evaluation
```{r male audio eval}
audio_eval_male <- read_delim(here("raw_data", "data_exp_86579-v59_task-ue28.csv"), col_names = TRUE, delim = ",")

### relevant columns for audio evaluations & rename

audio_eval_male%>%
  select(`Participant Public ID`, `UTC Date and Time`, `UTC Timestamp`, `Response Type`, `Response`, `Object Name`, `Task Name`, `Spreadsheet: Audio`, `Spreadsheet: Speaker`, `Spreadsheet: Speaker gender`, `Spreadsheet: Variety`,
         `Spreadsheet: Political orientation`, `Spreadsheet: Stimulus number`, `Spreadsheet: Stimulus1`, `Spreadsheet: Stimulus2`, `Spreadsheet: Stimulus3`, `Spreadsheet: Stimulus4`, `Spreadsheet: Stimulus5`, 
         `Spreadsheet: Stimulus6`, `Spreadsheet: Attention Check`, `Store: Attention Check`)%>%
  rename(Audio_Track = `Spreadsheet: Audio`, Speaker = `Spreadsheet: Speaker`, Speaker_Gender = `Spreadsheet: Speaker gender`, Lang.Variety_Audio = `Spreadsheet: Variety`,
         Polit_ori = `Spreadsheet: Political orientation`, Statement_no = `Spreadsheet: Stimulus number`, Att.check_acc = `Store: Attention Check`)%>%
  filter(`Response Type` == "response")%>%
  filter (str_starts(Speaker, "Exp"))->audio_eval_male

## remove markdown from values
audio_eval_male%>%
mutate(across(starts_with("Spreadsheet:"), ~ str_remove_all(., "\\*\\*")))-> audio_eval_male

## create one column with attribute related to rating
audio_eval_male%>%
mutate(Attribute = case_when(
  `Object Name` == "RatingScale_Stimulus1" ~ `Spreadsheet: Stimulus1`,
  `Object Name` == "RatingScale_Stimulus2" ~ `Spreadsheet: Stimulus2`,
  `Object Name` == "RatingScale_Stimulus3" ~ `Spreadsheet: Stimulus3`,
  `Object Name` == "RatingScale_Stimulus4" ~ `Spreadsheet: Stimulus4`,
  `Object Name` == "RatingScale_Stimulus5" ~ `Spreadsheet: Stimulus5`,
  `Object Name` == "RatingScale_Stimulus6" ~ `Spreadsheet: Stimulus6`,
  `Object Name` == "RatingScale_AttentionCheck" ~ `Spreadsheet: Attention Check`))->audio_eval_male

## delete unnecessary columns & elaborate levels of categorical variables
audio_eval_male%>%
  select(-starts_with("Spreadsheet:"), -`Response Type`)%>%
  mutate(Speaker_Gender = ifelse(Speaker_Gender=="f", "female", "male"))%>%
  mutate (Polit_ori = ifelse(Polit_ori == "l", "left", "right"))%>%
  mutate (Lang.Variety_Audio = ifelse(Lang.Variety_Audio == "st", "Standard German", "Regional Variety"))-> audio_eval_male

## Identify-final-accuracy
## select final response attention check accuracy
audio_eval_male %>%
  ungroup()%>%
  group_by(`Participant Public ID`) %>%
      mutate(Att.check_acc_last = last(Att.check_acc))%>%
  select(-Att.check_acc) %>%
  rename(Att.check_acc = Att.check_acc_last) -> audio_eval_male

## duplicates & data loss in audio_eval_male?
audio_eval_male%>%
  group_by(`Participant Public ID`)%>%
  count()-> pp_rows # 3 pp not normal row no of 168 but below (161 & 165) & above (189)

# select later response of pp depending on Time Stamp

audio_eval_male %>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
   filter(`UTC Timestamp` == max(`UTC Timestamp`))->audio_eval_male

## duplicates & data loss in audio_eval_male?
audio_eval_male%>%
  group_by(`Participant Public ID`)%>%
  count()-> pp_rows # 2pp below 168
```
## Origin & authenticity
```{r male origin authenticity_prep}
#read data
origin_authen_male <-read_delim(here("raw_data", "data_exp_86579-v59_task-brwb.csv"), col_names = TRUE, delim = ",")

#elaborate columns

origin_authen_male%>%
  select(`Participant Public ID`, `Response Type`, Response, `Spreadsheet: Display`, `Spreadsheet: Audio`, `Spreadsheet: Variety`, `Object ID`, `UTC Date and Time`, `UTC Timestamp`)%>%
  rename(Target = `Spreadsheet: Display`, Audio_origin_auth = `Spreadsheet: Audio`, Variety = `Spreadsheet: Variety`)%>%
  filter (`Response Type` == "response")%>%
  mutate(Target_Concept = case_when(
    Target == "Political level" ~ "Political level",
    Target == "Paradigm check" ~ "Paradigm check",
    Target == "Origin & authenticity" & grepl("^[0-9]+$", Response) & Variety == "non-st" ~ "proximity_variety_non-st",
    Target == "Origin & authenticity" & grepl("^[0-9]+$", Response) & Variety == "st" ~ "proximity_variety_st",
    Target == "Origin & authenticity" & !grepl("^[0-9]+$", Response) & Variety == "st" ~ "identity_lang.variety_st",
    Target == "Origin & authenticity" & !grepl("^[0-9]+$", Response) & Variety == "non-st" ~ "identity_lang.variety_non-st",
    TRUE ~ NA_character_))%>%
  filter(Response != "continue")%>%
  select(-`Response Type`, -Target)%>%
  select(`Participant Public ID`, Response, Target_Concept, Audio_origin_auth, Variety, `Object ID`, `UTC Date and Time`, `UTC Timestamp`)-> origin_authen_male
```
### clean open text "Paradigm Check"
```{r male orin_authen_para}
## separate Paradigm Check Level
origin_authen_male %>%
  mutate(
    Target_Concept = case_when(
      `Object ID` == "object-1145" ~ "Paradigm check 1",
      `Object ID` == "object-1146" ~ "Paradigm check 2",
      TRUE ~ Target_Concept)) -> origin_authen_male

# Identify  participants not deceived by the speaker illusion
## Preprocess answers to open text fields
origin_authen_male %>%
  mutate(Response_tidy = str_to_lower(Response)) -> origin_authen_male

## Create new variable (1 = deceived, 0 = not deceived)
origin_authen_male %>%
  mutate(deceived = ifelse(str_detect(Response_tidy, "(gleich|selb).{0,2} (person|sprecher|sprechende|stimme).*") |
           str_detect(Response_tidy, "(stimm).{0,2} (verstell).*"), 0, 1))%>%
  group_by(`Participant Public ID`) %>%
  mutate(deceived = case_when(
    any(deceived == 0) ~ 0,
    TRUE ~ deceived)) %>%
  ungroup() %>% 
  select(-Response_tidy) -> origin_authen_male
```
### origin & authenticity duplicates
```{r male origin authenticity_dupl}
## Check duplicates

origin_authen_male%>%
  group_by(`Participant Public ID`, Audio_origin_auth, Target_Concept) %>%
  summarise(n_distinct (`Participant Public ID`)) -> duplicates

origin_authen_male%>%
  group_by (`Participant Public ID`)%>%
  count(`Participant Public ID`)-> pp_bckgr_rows # normal 168 but 4 pp above & below

origin_authen_male%>%
  ungroup()%>%
  summarise(n_distinct(`Participant Public ID`))#446


origin_authen_male%>%
  filter (`Participant Public ID` == "281162358237373" | `Participant Public ID` == "281082304369845" | `Participant Public ID` == "281251938576386")-> check_pp
## => double ratings/ duplicated coz pp changed their rating at a later time OR pp selected "__other" and added answer to open Q field

### 1) select later response of pp depending on Time Stamp

origin_authen_male %>%
  group_by(`Participant Public ID`, Audio_origin_auth, Target_Concept) %>%
  filter(`UTC Timestamp` == max(`UTC Timestamp`))->origin_authen_male

## 2) if "_other" selected, next line text box entry into new column, then drop duplicated "_other"

origin_authen_male%>%
  mutate(Response_Text_identity_lang.var = ifelse(Response == "__other", lead(Response), NA))%>%
  ungroup()%>%
  filter(!(Response == "__other" & is.na(Response_Text_identity_lang.var)))%>%
  distinct(`Participant Public ID`, Audio_origin_auth, Target_Concept, Variety, .keep_all = TRUE)%>%
  select(-`Object ID`,-`UTC Date and Time`)->origin_authen_male
```
# Prep origin & authenticity join

```{r male origin authenticity_wide}

## turn long into wide format to match different data sets
origin_authen_male%>%
  pivot_wider(names_from = "Target_Concept",
              values_from = "Response")->origin_authen_male

## fill NAs with repeated values in new columns from origin_authen

# Explicitly define the new columns to be filled
new_columns_to_fill <- c("Political level",
                         "Paradigm check 1", "Paradigm check 2", "deceived", "Response_Text_identity_lang.var")

new_columns_to_fill2 <- c("proximity_variety_st", "proximity_variety_non-st", "identity_lang.variety_non-st", "proximity_variety_st", "identity_lang.variety_st")

# Fill missing values in the specified columns within each participant & dropping redundant columns

 origin_authen_male %>%
  group_by(`Participant Public ID`) %>%
  fill(all_of(new_columns_to_fill), .direction = "downup") %>%
  ungroup()->origin_authen_male
 
 origin_authen_male%>%
   filter(Audio_origin_auth != "NA")%>%
   filter(!(is.na(`proximity_variety_st`) & is.na(`proximity_variety_non-st`)))-> origin_authen_male
 
 origin_authen_male%>%
   group_by(`Participant Public ID`) %>%
  fill(all_of(new_columns_to_fill2), .direction = "downup")-> origin_authen_male
 
# make data set wider to have only one row per pp
 
 ## turn long into wide format to match different data sets
origin_authen_male%>%
  pivot_wider(names_from = "Variety",
              values_from = "Audio_origin_auth")->origin_authen_male

# fill NAs in columns to drop duplicates
columns_to_fill <- c("st","non-st")

origin_authen_male%>%
group_by(`Participant Public ID`) %>%
  fill(all_of(columns_to_fill), .direction = "downup")%>%
  ungroup()%>%
  select(-`UTC Timestamp`)%>%
  distinct()%>%
  rename(Audio_Track_origin_st = st)%>%
  rename (Audio_Track_origin_non_st = `non-st`)->origin_authen_male
```
## Combine 2 data sets: audio eval, origin & authenticity
```{r male combine tasks}
# not necessarily same audio in origin & authenticity like in audio eval, same speaker set though

audio_eval_male %>%
   left_join(origin_authen_male, join_by(`Participant Public ID`))-> combined_tasks_male 
```
# Check duplicates combined data
```{r male combine data dupl}

## Check duplicates
combined_tasks_male%>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  summarise(n_distinct(`Participant Public ID`))-> duplicates

combined_tasks_male%>%
  group_by (`Participant Public ID`)%>%
  count(`Participant Public ID`)-> combined_tasks_male_rows # normal 168 but 2 pp below


 combined_tasks_male %>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  filter(`UTC Timestamp` == max(`UTC Timestamp`)) %>%
  select(-`UTC Date and Time`, -`Object Name`) %>%
  distinct() %>%
  ungroup()-> combined_tasks_male


## Check duplicates
combined_tasks_male%>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  summarise(n = n(), .groups = "drop") %>%
  filter(n > 1L)-> duplicates # 0pp
```
# *Tasks female only*
## Audio evaluations 
```{r female audio_eval}
audio_eval_female <- read_delim(here("raw_data", "data_exp_86579-v59_task-v697.csv"), col_names = TRUE, delim = ",")  

### relevant columns for audio evaluations & rename

audio_eval_female%>%
  select(`Participant Public ID`, `UTC Date and Time`, `UTC Timestamp`, `Response Type`, `Response`, `Object Name`, `Task Name`, `Spreadsheet: Audio`, `Spreadsheet: Speaker`, `Spreadsheet: Speaker gender`, `Spreadsheet: Variety`,
         `Spreadsheet: Political orientation`, `Spreadsheet: Stimulus number`, `Spreadsheet: Stimulus1`, `Spreadsheet: Stimulus2`, `Spreadsheet: Stimulus3`, `Spreadsheet: Stimulus4`, `Spreadsheet: Stimulus5`, 
         `Spreadsheet: Stimulus6`, `Spreadsheet: Attention Check`, `Store: Attention Check`)%>%
  rename(Audio_Track = `Spreadsheet: Audio`, Speaker = `Spreadsheet: Speaker`, Speaker_Gender = `Spreadsheet: Speaker gender`, Lang.Variety_Audio = `Spreadsheet: Variety`,
         Polit_ori = `Spreadsheet: Political orientation`, Statement_no = `Spreadsheet: Stimulus number`, Att.check_acc = `Store: Attention Check`)%>%
  filter(`Response Type` == "response")%>%
  filter (str_starts(Speaker, "Exp"))->audio_eval_female

## remove markdown from values
audio_eval_female%>%
mutate(across(starts_with("Spreadsheet:"), ~ str_remove_all(., "\\*\\*")))-> audio_eval_female

## create one column with attribute related to rating
audio_eval_female%>%
mutate(Attribute = case_when(
  `Object Name` == "RatingScale_Stimulus1" ~ `Spreadsheet: Stimulus1`,
  `Object Name` == "RatingScale_Stimulus2" ~ `Spreadsheet: Stimulus2`,
  `Object Name` == "RatingScale_Stimulus3" ~ `Spreadsheet: Stimulus3`,
  `Object Name` == "RatingScale_Stimulus4" ~ `Spreadsheet: Stimulus4`,
  `Object Name` == "RatingScale_Stimulus5" ~ `Spreadsheet: Stimulus5`,
  `Object Name` == "RatingScale_Stimulus6" ~ `Spreadsheet: Stimulus6`,
  `Object Name` == "RatingScale_AttentionCheck" ~ `Spreadsheet: Attention Check`))->audio_eval_female

## delete unnecessary columns & elaborate levels of categorical variables
audio_eval_female%>%
  select(-starts_with("Spreadsheet:"), -`Response Type`)%>%
  mutate(Speaker_Gender = ifelse(Speaker_Gender=="f", "female", "male"))%>%
  mutate (Polit_ori = ifelse(Polit_ori == "l", "left", "right"))%>%
  mutate (Lang.Variety_Audio = ifelse(Lang.Variety_Audio == "st", "Standard German", "Regional Variety"))-> audio_eval_female

## Identify-final-accuracy
## select final response attention check accuracy
audio_eval_female %>%
  ungroup()%>%
  group_by(`Participant Public ID`) %>%
      mutate(Att.check_acc_last = last(Att.check_acc))%>%
  select(-Att.check_acc) %>%
  rename(Att.check_acc = Att.check_acc_last) -> audio_eval_female

## duplicates & data loss in audio_eval_female?
audio_eval_female%>%
  group_by(`Participant Public ID`)%>%
  count()-> pp_rows # 

# select later response of pp depending on Time Stamp

audio_eval_female %>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
   filter(`UTC Timestamp` == max(`UTC Timestamp`))->audio_eval_female

## duplicates & data loss in audio_eval_female?
audio_eval_female%>%
  group_by(`Participant Public ID`)%>%
  count()-> pp_rows # 1 pp not normal row no of 168 but below
```
## Origin & authenticity
```{r female origin_authenticity}
# read data
origin_authen_female <-read_delim(here("raw_data", "data_exp_86579-v59_task-8u1p.csv"), col_names = TRUE, delim = ",")

#elaborate columns

origin_authen_female%>%
  select(`Participant Public ID`, `Response Type`, Response, `Spreadsheet: Display`, `Spreadsheet: Audio`, `Spreadsheet: Variety`, `Object ID`, `UTC Date and Time`, `UTC Timestamp`)%>%
  rename(Target = `Spreadsheet: Display`, Audio_origin_auth = `Spreadsheet: Audio`, Variety = `Spreadsheet: Variety`)%>%
  filter (`Response Type` == "response")%>%
  mutate(Target_Concept = case_when(
    Target == "Political level" ~ "Political level",
    Target == "Paradigm check" ~ "Paradigm check",
    Target == "Origin & authenticity" & grepl("^[0-9]+$", Response) & Variety == "non-st" ~ "proximity_variety_non-st",
    Target == "Origin & authenticity" & grepl("^[0-9]+$", Response) & Variety == "st" ~ "proximity_variety_st",
    Target == "Origin & authenticity" & !grepl("^[0-9]+$", Response) & Variety == "st" ~ "identity_lang.variety_st",
    Target == "Origin & authenticity" & !grepl("^[0-9]+$", Response) & Variety == "non-st" ~ "identity_lang.variety_non-st",
    TRUE ~ NA_character_))%>%
  filter(Response != "continue")%>%
  select(-`Response Type`, -Target)%>%
  select(`Participant Public ID`, Response, Target_Concept, Audio_origin_auth, Variety, `Object ID`, `UTC Date and Time`, `UTC Timestamp`)-> origin_authen_female
```
### clean open text "Paradigm Check"
```{r female orin_authen_para}
## separate Paradigm Check Level
origin_authen_female %>%
  mutate(
    Target_Concept = case_when(
      `Object ID` == "object-1145" ~ "Paradigm check 1",
      `Object ID` == "object-1146" ~ "Paradigm check 2",
      TRUE ~ Target_Concept)) -> origin_authen_female

# Identify  participants not deceived by the speaker illusion
## Preprocess answers to open text fields
origin_authen_female %>%
  mutate(Response_tidy = str_to_lower(Response)) -> origin_authen_female

## Create new variable (1 = deceived, 0 = not deceived)
origin_authen_female %>%
  mutate(deceived = ifelse(str_detect(Response_tidy, "(gleich|selb).{0,2} (person|sprecher|sprechende|stimme).*") |
           str_detect(Response_tidy, "(stimm).{0,2} (verstell).*"), 0, 1))%>%
  group_by(`Participant Public ID`) %>%
  mutate(deceived = case_when(
    any(deceived == 0) ~ 0,
    TRUE ~ deceived)) %>%
  ungroup() %>% 
  select(-Response_tidy) -> origin_authen_female
```
### origin & authenticity duplicates
```{r female origin authenticity_dupl}
## Check duplicates

origin_authen_female%>%
  group_by(`Participant Public ID`, Audio_origin_auth, Target_Concept) %>%
  summarise(n_distinct (`Participant Public ID`)) -> duplicates

origin_authen_female%>%
  ungroup()%>%
  summarise(n_distinct(`Participant Public ID`))#418


## 1) select later response of pp depending on Time Stamp

origin_authen_female %>%
  group_by(`Participant Public ID`, Audio_origin_auth, Target_Concept) %>%
  filter(`UTC Timestamp` == max(`UTC Timestamp`))->origin_authen_female


## 2) if "_other" selected, next line text box entry into new column, then drop duplicated "_other"

origin_authen_female%>%
  mutate(Response_Text_identity_lang.var = ifelse(Response == "__other", lead(Response), NA))%>%
  ungroup()%>%
  filter(!(Response == "__other" & is.na(Response_Text_identity_lang.var)))%>%
  distinct(`Participant Public ID`, Audio_origin_auth, Target_Concept, Variety, .keep_all = TRUE)%>%
  select(-`Object ID`,-`UTC Date and Time`)->origin_authen_female
```
# Prep origin & authenticity join

```{r female origin authenticity_wide}

## turn long into wide format to match different data sets
origin_authen_female%>%
  pivot_wider(names_from = "Target_Concept",
              values_from = "Response")->origin_authen_female

## fill NAs with repeated values in new columns from origin_authen

# Explicitly define the new columns to be filled
new_columns_to_fill <- c("Political level",
                         "Paradigm check 1", "Paradigm check 2", "deceived", "Response_Text_identity_lang.var")

new_columns_to_fill2 <- c("proximity_variety_st", "proximity_variety_non-st", "identity_lang.variety_non-st", "proximity_variety_st", "identity_lang.variety_st")

# Fill missing values in the specified columns within each participant & dropping redundant columns

 origin_authen_female %>%
  group_by(`Participant Public ID`) %>%
  fill(all_of(new_columns_to_fill), .direction = "downup") %>%
  ungroup()->origin_authen_female
 
 origin_authen_female%>%
   filter(Audio_origin_auth != "NA")%>%
   filter(!(is.na(`proximity_variety_st`) & is.na(`proximity_variety_non-st`)))-> origin_authen_female
 
 origin_authen_female%>%
   group_by(`Participant Public ID`) %>%
  fill(all_of(new_columns_to_fill2), .direction = "downup")-> origin_authen_female
 
# make data set wider to have only one row per pp
 
 ## turn long into wide format to match different data sets
origin_authen_female%>%
  pivot_wider(names_from = "Variety",
              values_from = "Audio_origin_auth")->origin_authen_female

# fill NAs in columns to drop duplicates
columns_to_fill <- c("st","non-st")

origin_authen_female%>%
group_by(`Participant Public ID`) %>%
  fill(all_of(columns_to_fill), .direction = "downup")%>%
  ungroup()%>%
  select(-`UTC Timestamp`)%>%
  distinct()%>%
  rename(Audio_Track_origin_st = st)%>%
  rename (Audio_Track_origin_non_st = `non-st`)->origin_authen_female
```
## Combine 2 data sets: audio eval, origin & authenticity
```{r female combine tasks}
# not necessarily same audio in origin & authenticity like in audio eval, same speaker set though

audio_eval_female %>%
   left_join(origin_authen_female, join_by(`Participant Public ID`))-> combined_tasks_female 
```
# Check duplicates combined data
```{r female combine data dupl}

## Check duplicates
combined_tasks_female%>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  summarise(n_distinct(`Participant Public ID`))-> duplicates

combined_tasks_female%>%
  group_by (`Participant Public ID`)%>%
  count(`Participant Public ID`)-> combined_tasks_female_rows # normal 168 but 1 pp below


 combined_tasks_female %>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  filter(`UTC Timestamp` == max(`UTC Timestamp`)) %>%
  select(-`UTC Date and Time`, -`Object Name`) %>%
  distinct() %>%
  ungroup()-> combined_tasks_female

```
#*Tasks Male vs. Female tasks*
## Audio evaluation
```{r male_vs_female audio eval}
## read data
audio_eval_male_vs_female <-read_delim(here("raw_data", "data_exp_86579-v59_task-mdix.csv"), col_names = TRUE, delim = ",")

### relevant columns for audio evaluations & rename

audio_eval_male_vs_female%>%
  select(`Participant Public ID`, `UTC Date and Time`, `UTC Timestamp`, `Response Type`, `Response`, `Object Name`, `Task Name`, `Spreadsheet: Audio`, `Spreadsheet: Speaker`, `Spreadsheet: Speaker gender`, `Spreadsheet: Variety`,
         `Spreadsheet: Political orientation`, `Spreadsheet: Stimulus number`, `Spreadsheet: Stimulus1`, `Spreadsheet: Stimulus2`, `Spreadsheet: Stimulus3`, `Spreadsheet: Stimulus4`, `Spreadsheet: Stimulus5`, 
         `Spreadsheet: Stimulus6`, `Spreadsheet: Attention Check`, `Store: Attention Check`)%>%
  rename(Audio_Track = `Spreadsheet: Audio`, Speaker = `Spreadsheet: Speaker`, Speaker_Gender = `Spreadsheet: Speaker gender`, Lang.Variety_Audio = `Spreadsheet: Variety`,
         Polit_ori = `Spreadsheet: Political orientation`, Statement_no = `Spreadsheet: Stimulus number`, Att.check_acc = `Store: Attention Check`)%>%
  filter(`Response Type` == "response")%>%
  filter (str_starts(Speaker, "Exp"))->audio_eval_male_vs_female

## remove markdown from values
audio_eval_male_vs_female%>%
mutate(across(starts_with("Spreadsheet:"), ~ str_remove_all(., "\\*\\*")))-> audio_eval_male_vs_female

## create one column with attribute related to rating
audio_eval_male_vs_female%>%
mutate(Attribute = case_when(
  `Object Name` == "RatingScale_Stimulus1" ~ `Spreadsheet: Stimulus1`,
  `Object Name` == "RatingScale_Stimulus2" ~ `Spreadsheet: Stimulus2`,
  `Object Name` == "RatingScale_Stimulus3" ~ `Spreadsheet: Stimulus3`,
  `Object Name` == "RatingScale_Stimulus4" ~ `Spreadsheet: Stimulus4`,
  `Object Name` == "RatingScale_Stimulus5" ~ `Spreadsheet: Stimulus5`,
  `Object Name` == "RatingScale_Stimulus6" ~ `Spreadsheet: Stimulus6`,
  `Object Name` == "RatingScale_AttentionCheck" ~ `Spreadsheet: Attention Check`))->audio_eval_male_vs_female

## delete unnecessary columns & elaborate levels of categorical variables
audio_eval_male_vs_female%>%
  select(-starts_with("Spreadsheet:"), -`Response Type`)%>%
  mutate(Speaker_Gender = ifelse(Speaker_Gender=="f", "female", "male"))%>%
  mutate (Polit_ori = ifelse(Polit_ori == "l", "left", "right"))%>%
  mutate (Lang.Variety_Audio = ifelse(Lang.Variety_Audio == "st", "Standard German", "Regional Variety"))-> audio_eval_male_vs_female

## Identify-final-accuracy
## select final response attention check accuracy
audio_eval_male_vs_female %>%
  ungroup()%>%
  group_by(`Participant Public ID`) %>%
      mutate(Att.check_acc_last = last(Att.check_acc))%>%
  select(-Att.check_acc) %>%
  rename(Att.check_acc = Att.check_acc_last) -> audio_eval_male_vs_female

## duplicates & data loss in audio_eval_male_vs_female?
audio_eval_male_vs_female%>%
  group_by(`Participant Public ID`)%>%
  count()-> pp_rows # 

# select later response of pp depending on Time Stamp

audio_eval_male_vs_female %>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
   filter(`UTC Timestamp` == max(`UTC Timestamp`))->audio_eval_male_vs_female

## duplicates & data loss in audio_eval_male_vs_female?
audio_eval_male_vs_female%>%
  group_by(`Participant Public ID`)%>%
  count()-> pp_rows #
```
## Origin & authenticity
```{r male_vs_female origin & authenticity}
# read data
origin_authen_male_vs_female <-read_delim(here("raw_data", "data_exp_86579-v59_task-r61o.csv"), col_names = TRUE, delim = ",")

#elaborate columns

origin_authen_male_vs_female%>%
  select(`Participant Public ID`, `Response Type`, Response, `Spreadsheet: Display`, `Spreadsheet: Audio`, `Spreadsheet: Variety`, `Object ID`, `UTC Date and Time`, `UTC Timestamp`)%>%
  rename(Target = `Spreadsheet: Display`, Audio_origin_auth = `Spreadsheet: Audio`, Variety = `Spreadsheet: Variety`)%>%
  filter (`Response Type` == "response")%>%
  mutate(Target_Concept = case_when(
    Target == "Political level" ~ "Political level",
    Target == "Paradigm check" ~ "Paradigm check",
    Target == "Origin & authenticity" & grepl("^[0-9]+$", Response) & Variety == "non-st" ~ "proximity_variety_non-st",
    Target == "Origin & authenticity" & grepl("^[0-9]+$", Response) & Variety == "st" ~ "proximity_variety_st",
    Target == "Origin & authenticity" & !grepl("^[0-9]+$", Response) & Variety == "st" ~ "identity_lang.variety_st",
    Target == "Origin & authenticity" & !grepl("^[0-9]+$", Response) & Variety == "non-st" ~ "identity_lang.variety_non-st",
    TRUE ~ NA_character_))%>%
  filter(Response != "continue")%>%
  select(-`Response Type`, -Target)%>%
  select(`Participant Public ID`, Response, Target_Concept, Audio_origin_auth, Variety, `Object ID`, `UTC Date and Time`, `UTC Timestamp`)-> origin_authen_male_vs_female
```
### clean open text "Paradigm Check"
```{r male_vs_female orin_authen_para}
## separate Paradigm Check Level
origin_authen_male_vs_female %>%
  mutate(
    Target_Concept = case_when(
      `Object ID` == "object-1145" ~ "Paradigm check 1",
      `Object ID` == "object-1146" ~ "Paradigm check 2",
      TRUE ~ Target_Concept)) -> origin_authen_male_vs_female

# Identify  participants not deceived by the speaker illusion
## Preprocess answers to open text fields
origin_authen_male_vs_female %>%
  mutate(Response_tidy = str_to_lower(Response)) -> origin_authen_male_vs_female

## Create new variable (1 = deceived, 0 = not deceived)
origin_authen_male_vs_female %>%
  mutate(deceived = ifelse(str_detect(Response_tidy, "(gleich|selb).{0,2} (person|sprecher|sprechende|stimme).*") |
           str_detect(Response_tidy, "(stimm).{0,2} (verstell).*"), 0, 1))%>%
  group_by(`Participant Public ID`) %>%
  mutate(deceived = case_when(
    any(deceived == 0) ~ 0,
    TRUE ~ deceived)) %>%
  ungroup() %>% 
  select(-Response_tidy) -> origin_authen_male_vs_female
```
### origin & authenticity duplicates
```{r male_vs_female origin authenticity_dupl}
## Check duplicates

origin_authen_male_vs_female%>%
  group_by(`Participant Public ID`, Audio_origin_auth, Target_Concept) %>%
  summarise(n_distinct (`Participant Public ID`)) -> duplicates

origin_authen_male_vs_female%>%
  ungroup()%>%
  summarise(n_distinct(`Participant Public ID`))#


## 1) select later response of pp depending on Time Stamp

origin_authen_male_vs_female %>%
  group_by(`Participant Public ID`, Audio_origin_auth, Target_Concept) %>%
  filter(`UTC Timestamp` == max(`UTC Timestamp`))->origin_authen_male_vs_female


## 2) if "_other" selected, next line text box entry into new column, then drop duplicated "_other"

origin_authen_male_vs_female%>%
  mutate(Response_Text_identity_lang.var = ifelse(Response == "__other", lead(Response), NA))%>%
  ungroup()%>%
  filter(!(Response == "__other" & is.na(Response_Text_identity_lang.var)))%>%
  distinct(`Participant Public ID`, Audio_origin_auth, Target_Concept, Variety, .keep_all = TRUE)%>%
  select(-`Object ID`,-`UTC Date and Time`)->origin_authen_male_vs_female
```
# Prep origin & authenticity join

```{r male_vs_female origin authenticity_wide}

## turn long into wide format to match different data sets
origin_authen_male_vs_female%>%
  pivot_wider(names_from = "Target_Concept",
              values_from = "Response")->origin_authen_male_vs_female

## fill NAs with repeated values in new columns from origin_authen

# Explicitly define the new columns to be filled
new_columns_to_fill <- c("Political level",
                         "Paradigm check 1", "Paradigm check 2", "deceived", "Response_Text_identity_lang.var")

new_columns_to_fill2 <- c("proximity_variety_st", "proximity_variety_non-st", "identity_lang.variety_non-st", "proximity_variety_st", "identity_lang.variety_st")

# Fill missing values in the specified columns within each participant & dropping redundant columns

 origin_authen_male_vs_female %>%
  group_by(`Participant Public ID`) %>%
  fill(all_of(new_columns_to_fill), .direction = "downup") %>%
  ungroup()->origin_authen_male_vs_female
 
 origin_authen_male_vs_female%>%
   filter(Audio_origin_auth != "NA")%>%
   filter(!(is.na(`proximity_variety_st`) & is.na(`proximity_variety_non-st`)))-> origin_authen_male_vs_female
 
 origin_authen_male_vs_female%>%
   group_by(`Participant Public ID`) %>%
  fill(all_of(new_columns_to_fill2), .direction = "downup")-> origin_authen_male_vs_female
 
# make data set wider to have only one row per pp
 
 ## turn long into wide format to match different data sets
origin_authen_male_vs_female%>%
  pivot_wider(names_from = "Variety",
              values_from = "Audio_origin_auth")->origin_authen_male_vs_female

# fill NAs in columns to drop duplicates
columns_to_fill <- c("st","non-st")

origin_authen_male_vs_female%>%
group_by(`Participant Public ID`) %>%
  fill(all_of(columns_to_fill), .direction = "downup")%>%
  ungroup()%>%
  select(-`UTC Timestamp`)%>%
  distinct()%>%
  rename(Audio_Track_origin_st = st)%>%
  rename (Audio_Track_origin_non_st = `non-st`)->origin_authen_male_vs_female
```
## Combine 2 data sets: audio eval, origin & authenticity
```{r male_vs_female combine tasks}
# not necessarily same audio in origin & authenticity like in audio eval, same speaker set though

audio_eval_male_vs_female %>%
   left_join(origin_authen_male_vs_female, join_by(`Participant Public ID`))-> combined_tasks_male_vs_female 
```
# Check duplicates combined data
```{r female combine data dupl}

## Check duplicates
combined_tasks_male_vs_female%>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  summarise(n_distinct(`Participant Public ID`))-> duplicates

combined_tasks_male_vs_female%>%
  group_by (`Participant Public ID`)%>%
  count(`Participant Public ID`)-> combined_tasks_male_vs_female_rows # normal 112 1pp 119


 combined_tasks_male_vs_female %>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  filter(`UTC Timestamp` == max(`UTC Timestamp`)) %>%
  select(-`UTC Date and Time`, -`Object Name`) %>%
  distinct() %>%
  ungroup()-> combined_tasks_male_vs_female
```
# combine all task data

```{r combine data all}

bind_rows(combined_tasks_female, combined_tasks_male, combined_tasks_male_vs_female)->data_tasks

# check duplicates

data_tasks%>%
  ungroup()%>%
  summarise(n_distinct(`Participant Public ID`))

data_tasks%>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  summarise(n = n()) %>%
  filter(n > 1L)-> duplicates

as.factor(data_tasks$`Task Name`)->data_tasks$`Task Name`
data_tasks%>%
  ungroup()%>%
 count(`Task Name`,`Speaker_Gender`,`Participant Public ID`)-> rows_per_condition

```
# *Background Questionnaire*
## Prep
```{r questionnaire1-Prep}

## read data
questionnaire <- read_delim(here("raw_data", "data_exp_86579-v59_questionnaire-ry6q.csv"), col_names = TRUE, delim = ",")
as_tibble(questionnaire)

# get relevant columns'

questionnaire%>%
  filter(`Event Index` != "END OF FILE")%>%
  select ("Participant Public ID", "Participant Status", "UTC Timestamp", "Participant OS", "Participant Browser", "Task Name", "counterbalance-nimi", "counterbalance-x3xi", "counterbalance-xq3l", "randomiser-rtb5", "age", "gender", "state_of_residence", "education_school", "education_profession1", "education_profession2", "income", "profession", "profession-text", starts_with("languages_caregiver1"), starts_with("languages_caregiver2"), starts_with("political_"), "other_languages", "own_dialect", "own_dialect-quantised", "party", "party-text", "party-quantised", matches("^social_desirability_[A-I]-quantised$"), matches("^populism_[A-D]$"))%>%
  select(-`political_orientation_A-quantised`, -`political_orientation_B-quantised`, -`political_orientation_C-quantised`, -`political_orientation_D-quantised`, -`political_spectrum_other-quantised`)%>%
  distinct()-> questionnaire

# prep: assign classes
as.factor(questionnaire$`Participant Public ID`)->questionnaire$`Participant Public ID`
as.numeric(questionnaire$age)->questionnaire$age
as.factor(questionnaire$gender)->questionnaire$gender
as.factor(questionnaire$state_of_residence)->questionnaire$state_of_residence
as.factor(questionnaire$education_school)->questionnaire$education_school
as.factor(questionnaire$education_profession1)->questionnaire$education_profession1
as.factor(questionnaire$education_profession2)->questionnaire$education_profession2
as.factor(questionnaire$income)->questionnaire$income
as.factor(questionnaire$profession)->questionnaire$profession
as.numeric(questionnaire$political_spectrum)->questionnaire$political_spectrum
as.numeric(questionnaire$own_dialect)->questionnaire$own_dialect
as.factor(questionnaire$party)->questionnaire$party

```
## identify multiple participation

```{r questionnaire2-Multi}
questionnaire %>%
  group_by (`Participant Public ID`)%>%
  summarise (n_distinct (`UTC Timestamp`))-> multi_part 

```
## create new dummy variables education
```{r questionnaire2-pp_bckgr}

questionnaire%>%
  mutate (education_profession1_sum = case_when
          (education_profession1 == "Berufsfachschulabschluss" ~ "low",
            education_profession1 == "Fachhochschulabschluss" ~ "high",
            education_profession1 == "Fachschulabschluss" ~ "middle",
            education_profession1 == "Hochschulabschluss (Bachelor)" ~ "high",
            education_profession1 == "Hochschulabschluss (Master)" ~ "high",
            education_profession1 == "Hochschulabschluss (Promotion)" ~ "high",
            education_profession1 == "Keinen" ~ "low",
            education_profession1 == "Meister/in, Technikerabschluss" ~ "middle",
            education_profession1 == "Teilfacharbeiterabschluss" ~ "low",
            education_profession1 == "Abgeschlossene gewerbliche oder landwirtschaftliche Lehre" ~ "middle",
            education_profession1 == "Abgeschlossene kaufmännische Lehre" ~ "middle",
            education_profession1 == "beruflich-betriebliche Anlernzeit mit Abschlusszeugnis, aber keine Lehre" ~ "low", TRUE ~ NA))-> questionnaire


questionnaire%>%
  mutate (education_school_sum = case_when
          (education_school == "Schule beendet ohne Abschluss"  ~ "low",
            education_school == "Hauptschulabschluss/ Volksschulabschluss/ Abschluss der polytechnischen Oberschule 8. oder 9. Klasse" ~ "low",
            education_school == "Realschulabschluss/ Mittlere Reife/ Fachschulreife oder Abschluss der polytechnischen Oberschule 10. Klasse" ~ "middle",
            education_school == "Fachhochschulreife (Abschluss einer Fachoberschule etc.)" ~ "high",
            education_school == "Abitur bzw. erweiterte Oberschule mit Abschluss 12. Klasse (Hochschulreife)" ~ "high",
            education_school == "bin noch Schüler/in" ~ "still at school",
            education_school == "andere" ~ "other",
            education_school == "NA" ~ "NA", TRUE ~ NA))-> questionnaire

questionnaire%>%
  group_by (`Participant Public ID`)%>%
  count(`Participant Public ID`)-> questionnaire_rows # 1 per pp

questionnaire%>%
  ungroup()%>%
  summarise(n_distinct(`Participant Public ID`))#1315
```
# combine questionaire with task data
```{r question_task_combine}
# assign classes
as.factor(data_tasks$`Participant Public ID`)->data_tasks$`Participant Public ID`
as.factor(questionnaire$`Participant Public ID`)->questionnaire$`Participant Public ID`

# Check for common Participant Public ID values
common_ids <- intersect(data_tasks$`Participant Public ID`, questionnaire$`Participant Public ID`)

# Display the number of common IDs
length(common_ids)

# perform join

data_tasks %>%
  left_join(questionnaire, join_by(`Participant Public ID`))->data_all
```
# wide to long & caregiver & lang variables
```{r questionnaire_wide_to_long}
data_all%>%
select(-"party-quantised", -"own_dialect-quantised", -"Task Name.y")%>%
filter (`Participant Public ID` != "280475315358931")->data_wide # discard Test Bilendi PP 280475315358931

# turn wide into long and create new sum-up lang.variety variable

data_wide%>%
  pivot_longer(cols = 41:84, names_to = "variety_numeric", values_to = "lang.variety")%>%
  drop_na(lang.variety)%>%
  distinct()->data_long

# new column open answer text box "Other dialect"

data_long%>%
  mutate(Response_Text_Other_Dialect = ifelse(lang.variety == "Anderer Dialekt", lag(lang.variety), NA))%>%
  filter(`variety_numeric` != "languages_caregiver2-text" &`variety_numeric`!= "languages_caregiver1-text" )%>%
  ungroup()-> data_long


# new colum lang.exposure & caregiver
data_long%>%
  mutate(caregiver= ifelse (str_detect(variety_numeric, "^languages_caregiver1"), "caregiver1", "caregiver2"))->data_long

data_long%>%
  pivot_wider(names_from = caregiver, values_from = lang.variety)%>%
  mutate (lang.exposure = ifelse(is.na(caregiver1), caregiver2,caregiver1 ))->data_long

data_long%>%
  ungroup()%>%
  select(-caregiver1, -caregiver2, -variety_numeric)%>%
  distinct()-> data_all


data_all%>%
  group_by(`Participant Public ID`, Audio_Track, Attribute, lang.exposure) %>%
  summarise(n = n()) %>%
  filter(n > 1L)-> duplicates # no

data_all%>%
  group_by(`Participant Public ID`, Audio_Track, Attribute) %>%
  summarise(n = n()) %>%
  filter(n > 1L)-> duplicates # between 2 - 10 # pp = 281162358882340 same entry for lang. variety  10 times

data_all%>%
  filter (`Participant Public ID` == 281162358882340)->pp_check # 10 times lang variety same time stamp



# Check NAs
data_all %>%
  ungroup()%>%
  summarise(
    na_Participant_Public_ID = sum(is.na(`Participant Public ID`)),
    na_Audio_Track = sum(is.na(Audio_Track)),
    na_Attribute = sum(is.na(Attribute)))->na_data_task

data_all %>%
  ungroup()%>%
  summarise(
    na_Participant_Public_ID = sum(is.na(`Participant Public ID`)),
    na_lang.variety = sum(is.na(lang.exposure)))->na_compl_questionnaire
```

# Standardise open text answer caregiver language
```{r questionnaire3-lang_pop_standardise, eval=FALSE, include=FALSE}

pp_lang_pop %>%
  mutate(Response_Text_Other_Dialect_check = ifelse(!is.na(Response_Text_Other_Dialect), str_to_lower(Response_Text_Other_Dialect), NA))-> pp_lang_pop
  

pp_lang_pop_test %>%
  mutate(lang.caregivers_sub = case_when(
    Response_Text_Other_Dialect %in% c("Berlin", "Berliner", "Berliner Deutsch", "Berliner Dialekt", "Berlinerisch") ~ "Berlinerisch",
   Response_Text_Other_Dialect %in% c("Ruhrgebiet", "Ruhrpott", "Ruhrpottslang", "Ruhrdeutsch") ~ "Ruhrdeutsch",
    Response_Text_Other_Dialect %in% c("Brandenburg", "Brandenburgisch") ~ "Brandenburgisch",
    Response_Text_Other_Dialect %in% c("Fränkisch", "Plattdeutsch", "Bayrisch") ~ NA_character_,
    TRUE ~ Response_Text_Other_Dialect
  )) -> pp_lang_pop_test

#### sort answers into existing categories
pp_lang_pop_special %>%
  mutate(lang.caregivers_hom = case_when(
    `languages_caregivers-text` %in% c("Bayrisch", "Münchnerisch") ~ "Bairisch",
    lang.caregivers_sub == "Berlinerisch" ~ "Ostdeutsch",
    `languages_caregivers-text` %in% c("Russisch", "Ungarisch", "Venezianisch", "Polnisch") ~ "Dialekt/Sprache aus dem nicht-deutschsprachigen Ausland",
    `languages_caregivers-text` %in% c("Ruhrgebiet", "Ruhrpott", "Ruhrpottslang", "Ruhrdeutsch") ~ "Ruhrdeutsch",
    `languages_caregivers-text` %in% c("Mannheimerisch", "Oberpfälzerisch", "Kurpfälzisch") ~ "Pfälzisch",
    `languages_caregivers-text` == "Rheinhessisch" ~ "Hessisch",
    `languages_caregivers-text` %in% c("Niederösterreichisch", "Wienerisch") ~ "Österreichisch",
    `languages_caregivers-text` %in% c("Schlesisch", "Oberlausitzer Dialekt", "Vogtlandisch (Fränkisch)", "Niederlausitzer Mundart", "Brandenburg", "Brandenburgisch", "Erzgebirgisch") ~ "Ostdeutsch",
    `languages_caregivers-text` %in% c("Siegerländer Plattdeutsch", "Eifeler Deutsch") ~ "Moselfränkisch",
    `languages_caregivers-text` == "Kölsch" ~ "Rheinisch",
    `languages_caregivers-text` == "Fränkisch" ~ "Fränkisch",
    `languages_caregivers-text` == "Plattdeutsch" ~ "Plattdeutsch"
    )) -> pp_lang_pop_special
```
# Transform lang. exposure into new variable in-/ outgroup lang. variety
```{r in_vs_outgroup, echo=TRUE}
as.factor(data_all$lang.exposure)->data_all$lang.exposure
levels(data_all$lang.exposure)

data_all%>%
  group_by(`Participant Public ID`)%>%
  mutate (lang.exposure = case_when(lang.exposure == "Schwäbisch" ~ "in-group",
                                    lang.exposure == "Alemannisch" | lang.exposure == "Anderer Dialekt"| lang.exposure == "Badisch"  |  lang.exposure == "Bairisch" |lang.exposure ==  "Fränkisch" | lang.exposure == "Hessisch" |                          lang.exposure == "Moselfränkisch" | lang.exposure ==  "Norddeutsch" | lang.exposure == "Ostdeutsch"  |  lang.exposure == "Österreichisch" | lang.exposure == "Pfälzisch" |  lang.exposure ==  "Plattdeutsch" | lang.exposure ==  "Rheinisch" | lang.exposure == "Saarländisch" |  lang.exposure ==  "Sächsisch" |lang.exposure == "Schweizerdeutsch" | lang.exposure == "Thüringisch" ~ "out-group_dialect", 
  lang.exposure == "Dialekt/Sprache aus dem nicht-deutschsprachigen Ausland" ~ "multilingual", lang.exposure == "Hochdeutsch"  ~ "standard_variety ", lang.exposure == "Ich weiß nicht" ~ "Ich weiß nicht", 
      FALSE ~ NA))->  data_all  

as.factor(data_all$lang.exposure)->data_all$lang.exposure
levels(data_all$lang.exposure)

data_all%>%
  select(-Response_Text_Other_Dialect)%>%
  distinct()->data_all

```
# Final data set
```{r check_final_data}
colnames(data_all)

# NAs

data_all%>%
  group_by(`Participant Public ID`) %>%
  summarise(na_count_pop_A = sum(is.na(populism_A)), na_count_pop_B = sum(is.na(populism_B)), na_count_pop_C = sum(is.na(populism_C)), na_count_pop_D = sum(is.na(populism_D)))->NA_pop

data_all%>%
  group_by(`Participant Public ID`) %>%
  summarise(na_count_lang.expo = sum(is.na(lang.exposure)), na_count_own_dialect = sum(is.na(own_dialect)), na_count_party= sum(is.na(party)))->NA_quest


# levels complete of questionnaire

data_all%>%
  group_by(`Task Name.x`, `Participant Public ID`)%>%
  count()-> pp_rows # works 112 for male vs female 168 for only condition but some pp 504

data_all%>%
  filter(`Participant Public ID`== "281348585493685")%>%
  select(`Participant Public ID`, Audio_Track, Attribute, Response, gender, age, party, `UTC Timestamp.y`, lang.exposure)->pp_check

levels(pp_check$lang.exposure)



## check randomization:

data_all%>%
  group_by(`randomiser-rtb5`,`counterbalance-nimi`, `counterbalance-x3xi`, `counterbalance-xq3l`)%>%
  summarise(n_distinct(`Participant Public ID`))->random


## check: participant background

### federal state

data_all%>%
  group_by(state_of_residence)%>%
  summarise(n_distinct(`Participant Public ID`))->pp_state

### participant age

data_all%>%
  ungroup()%>%
  drop_na(age)%>%
  summarise(mean(age), sd(age), min (age), max (age))->pp_age

### participant gender

data_all%>%
  group_by(gender)%>%
  summarise(n_distinct(`Participant Public ID`))->pp_gender

### sum_education_school
data_all%>%
  ungroup()%>%
  group_by(education_school_sum)%>%
  summarise(n_distinct(`Participant Public ID`))->sum_education

### education
data_all%>%
  group_by(education_school)%>%
  summarise(n_distinct(`Participant Public ID`))->education

### sum_profession
data_all%>%
  group_by(education_profession1_sum)%>%
  summarise(n_distinct(`Participant Public ID`))->sum_profession1


### income

data_all%>%
  group_by(income)%>%
  summarise(n_distinct(`Participant Public ID`))->income

### profession

data_all%>%
  group_by(profession)%>%
  summarise(n_distinct(`Participant Public ID`))->sum_profession

# gender

data_all%>%
  group_by(gender)%>%
  summarise(n_distinct(`Participant Public ID`))->pp_gender

# language

data_all%>%
  group_by(lang.exposure)%>%
  summarise(n_distinct(`Participant Public ID`))->sum_lang.exposure

data_all%>%
  ungroup()%>%
    drop_na(own_dialect)%>%
  summarise(mean(own_dialect), sd (own_dialect), min (own_dialect), max(own_dialect))->own_lang.variety 

# party

data_all%>%
  group_by(party)%>%
  summarise(n_distinct(`Participant Public ID`))->sum_party


data_all%>%
  group_by (`Participant Public ID`)%>%
  count(`Participant Public ID`)-> combined_q_rows # 1-14 rows per pp
# 281162358882340



data_all%>%
  ungroup()%>%
  summarise(n_distinct(`Participant Public ID`))#1313

```
# Write Final data set

```{r write csv final data}

write_delim(data_all, here("data_processed", "data_clean.csv"), col_names = TRUE, delim = ",")
```

